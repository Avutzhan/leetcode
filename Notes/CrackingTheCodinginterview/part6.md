
#О большое

Очень важная тема

###Временная сложность == Асимптотическая сложность == О большое

O, Θ и Ω

O - Верхняя граница сложности. Худший случай
Ω - Нижняя граница. Лучший случай
Θ - Тоная граница сложности. В Среднем одно и то же что и О Худший случай

###Лучший, Худший, Средний (Ожидаемый)

###Пространственная сложность

Обьем памяти в работе с массивами

Обьем памяти в стеке в работе с рекурсиями

###Константы

Синтаксис «О» большого описывает только скорость роста. По этой
причине константы исключаются из описания сложности. Запись вида O(2N) со-
кращается до O(N).

###Исключение второстепенных факторов

Второстепенные (не доминирующие) факторы исключаются из выражения:
* O(N 2 + N) превращается в O(N 2 ).
* O(N + log N) превращается в O(N).
* O(5*2 N + 1000N 100 ) превращается в O(2 N )

Это не означает, что в выражении сложности не может быть суммы. Например, вы-
ражение O(B 2 + A) сократить не удастся (без дополнительной информации об A и B).

Существует много других вариантов сложности,
худших O(x!), например O(x x ) или O(2 x * x!).

###Составные алгоритмы: сложение и умножение

O(A + B) когда два цикла

O(A * B) когда два вложенных цикла

###Амортизированное время

Принцип "amortized complexity" заключается в том, что,
хотя что-то может быть довольно сложным, когда вы это делаете,
поскольку это делается не очень часто, это считается "not complex".
Например, если вы создаете двоичное дерево, которое время от времени
нуждается в балансировке - скажем, один раз в 2^n вставках, -
потому что, хотя балансировка дерева довольно сложна, она
происходит только один раз в каждом n вставках (например, один
раз при вставке номер 256, затем снова при 512-й, 1024-й и т. д.).
Для всех остальных вставок сложность равна O(1) - Да,
она принимает O(n) один раз за каждые n вставок, но это всего
лишь вероятность 1/n , - поэтому мы умножаем O(n) на 1/n и получаем
O (1). Таким образом, это называется "Amortized complexity of O(1)" -
потому что, когда вы добавляете больше элементов, время, затрачиваемое
на перебалансировку дерева, минимально.

###Сложность Log N

когда вы встречаете задачу, в которой количество
элементов последовательно делится надвое, скорее всего, время выполнения со-
ставит O(log N).

###Сложность рекурсивных алгоритмов

```python
int f(int n) {
    if (n <= 0) {
        return 1;
    }
    return f(n - 1) + f(n - 1);
}
```

Постарайтесь запомнить эту закономерность. Если вы используете рекурсивную
функцию, которая порождает несколько вызовов, время выполнения часто (хотя
и не всегда) имеет вид O(ветви глубина ), где ветви — количество ветвлений при каждом
рекурсивном вызове. В нашем примере получается O(2 N ).

Как было сказано ранее, основание логарифма для «О» не имеет большого значения, так как ло-
гарифмы по разным основаниям различаются только постоянным множителем. С другой стороны,
к экспоненте это не относится; основание экспоненты имеет значение. Сравните 2 n и 8 n . Раскрыв
8 n , получаем (2 3 ) n , то есть 2 3n , или 2 2n * 2 n . Как видите, 8 n и 2 n отличаются множителем 2 2n — ничего
общего с постоянным множителем!

Пространственная сложность этого алгоритма составит O(N). Хотя дерево в сумме
содержит O(2 N ) узлов, в любой момент существуют только O(N) узлов. Следова-
тельно, затраты памяти ограничиваются величиной O(N).
